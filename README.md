# SRE Code Challenge - Go Outyet Webservice

This Terraform config deploys the outyet webservice infrastructure. It's a webservice that tells you if a version of golang has been released. The webservice is designed to be highly available in a single AWS region.

Related repos:
- https://github.com/mujahidhemani/packer-aws-srecc-outyet
- https://github.com/mujahidhemani/terraform-aws-srecc-cloudflare-dns
- https://github.com/mujahidhemani/terraform-aws-srecc-load-balancer
- https://github.com/mujahidhemani/terraform-aws-srecc-vpc
- https://github.com/mujahidhemani/terraform-aws-srecc-ec2-autoscale

## Prerequisites

- AWS account with CLI access keys
- Cloudflare free account with CLI access token
- Terraform 0.12
- TLS cert pre-created on AWS ACM
- DNS zone pre-created on Cloudflare

## How This Works

The Terraform config creates an Application Load Balancer (with target groups, listeners, etc), EC2 Autoscaling Group (with EC2 Instances, launch configs, etc), NAT Gateways for each backend subnet, Internet Gateway, VPC, frontend and backend subnets for 3 availability zones (one subnet of each type per AZ). It also creates a CloudFlare CNAME friendly record to alias to the ALB's autogenerated public record.


### Other Architecture/Design Notes

- Packer builds the outyet AMI. It's based on the Amazon Linux 2 AMI 
- Ansible is the provisioner used to configure the AMI
- Packer publishes the AMI, making it available to anyone who wants to clone this repo and run `terraform apply`; without having to build their own AMI
- A Vagrantfile is included to test the Ansible playbook locally in Vagrant

- TLS termination is done on the ALB, with the TLS policy `ELBSecurityPolicy-2016-08`. It is the default policy for the ALB and allows for a wide compatiblity with different HTTP clients/browsers due to the wide number of TLS versions and ciphers allowed. 
- The ALB has both HTTP and HTTPS listeners on ports 80/443. The HTTP listener will redirect all queries to HTTPS to ensure all requests are encrypted via TLS. The traffic from the HTTPS listeners is forwarded to healthy EC2 autoscaling instances registered in the ALB's target group on port 8080
- The EC2 instances communicate out to the Internet via their NAT Gateways to retrieve a YES or No response from Google if the queried version of golang is released (by default it checks to see if `1.4` is released which should always return YES)

- The name of the EC2 Autoscaling group is interpolated from the autogenerated name of it's associated launch configuration. This method ensures that updates to the launch configuration (such as using a new AMI) will trigger a replacement autoscaling group automatically on a Terraform run
- Using lifecycle rules (create before destroy) on both the autoscaling group and the launch configuration ensures that's there is no interruption to the web service as the autoscaling group and launch config are replaced

- CloudFlare was only used for DNS because AWS Free Tier does NOT include Route53
- CloudFlare also provides TLS termination through their CDN, but for the purposes of this project, it's disabled

- Terraform modules were created to allow version control of individual pieces of infrastructure
- As this project was iterated, different modules consisting of the frontend (load balancer), backend (autoscaling) and the VPC were developed indepenently of each other.
- The modules (with a little bit of further refactor to remove some hardcoded values) should be reusable for other projects
- All Terraform modules developed and used are available in the Registry: https://registry.terraform.io/search?q=mujahidhemani
- Terraform Cloud was integrated with this repo to maintain a production version of this service at http://go.outyet.info
- Development was done using local state storage without affecting the production version

### Outyet Binary Handling

The AMI that the Autoscaling group was created by Packer with an Ansible provisioner. It configures an Amazon Linux 2 AMI with golang, git and wget installed; as well as creates a service user called `outyet` to run the app. It also handles the installation of the outyet golang app using `go get`. A systemd service unit file is also included so that `outyet` runs when the AMI is launched in the EC2 Autoscaling cluster. Using Packer was the simplest and quickest way of handling the outyet binary and the configuration of the AMI. As everything in the AMI is prebuilt, you can scale up quickly as the warmup time is reduced!

To further iterate, a CI pipeline job (using CircleCI or GitHub Actions or similar services) can be created to automate the build of the AMI. Using the AMI ID output from that CI job could trigger a Terraform run to update the launch config, which will create a new autoscaling group with the updated AMI.

### Scaling Considerations

As mentioned in the previous section, using Packer to build the AMI allows you to scale using EC2 Autoscaling quickly, because you don't have to wait on configuration management to configure instances as they're launched. The autoscaling Terraform module can be improved to add an autocaling policy and appropriate CloudWatch metrics to dynamically scale instances based on traffic or CPU load. To maintain high availabilty a placement group (with the `Spread` strategy) would also need to be created to ensure that EC2 Autoscaling instances in the same AZ are on distinct underlying hardware. This will reduce downtime if the underlying hardware in an AZ fails.

However, configuration management would still be needed to patch the EC2 instances on an ongoing basis to ensure the OS is secured. You can remove the overhead of managing multiple EC2 instances and running configuration management by refactoring outyet into a Lambda function. Running as a Lambda function, you can free yourself from the overhead of managing operating systems potentially reduce costs of the service. Cold start times for golang Lambdas are incredibly low, as low as 200 milliseconds!

### Security 

As the EC2 instances run in backend (private) subnets, they don't have public IPs and therefore they are not publicly accessible. Also, the security group configured only allows inbound traffic on port 8080 to other members of the backend app security group (which in this case is the ALB). This ensures that no malicious access can come into the EC2 instances from the Internet. The EC2 Autoscaling group does not have any IAM roles assigned, so the instances should not be able to initiate any AWS actions. 

The Packer build relies on the Amazon Linux 2 AMI, if that is compromised (for example with malicious binaries that provide false application responses, or CPU coin miner); it will also affect the outyet web service. The default sudoers file is also not changed in the packer template, which gives passwordless sudo for all actions for the default `ec2-user` on the AMI, which a malicious script inserted into the Packer build or upstream from Amazon could take advantage of.

## Predeployment Steps

NOTE:
- If you plan to deploy multiple copies of this web service in the same AWS account, please ensure the following AWS limits are increased: EC2 instances (t2.micro), NAT gateways, Elastic IPs
- This guide assumes that Terraform 0.12 is installed
- This guide assumes that AWS CLI is already installed and access keys configured in the default profile
- This guide assumes that you've already created a Cloudflare token to be used by Terraform with the following permissions applied to all zones:
```
 Zone.Zone Read
 Zone.DNS  Edit
```

Step 0: Clone this repo: `git clone git@github.com:mujahidhemani/terraform-aws-srecc-outyet.git`

### Setup a Cloudflare Zone

NOTE: You will need to use a domain you already own for this. 

1. Login to your Cloudflare account at https://dash.cloudflare.com
2. From Home, click on Add Site
3. Enter your domain and click Add site
4. Select the Free plan level and click Confirm plan
5. Cloudflare will scan to see if there are any DNS records to import; if this is an empty zone create a TXT record, with the record name `demo` and value `test` and click Continue
6. The page will now display your nameserver records. In your domain registrar's portal, update the NS records to the ones from Cloudflare. This mnay take some time to propogate to DNS servers globally. 

Once you have finished adding your zone to Cloudflare, return to Cloudflare Home at https://dash.cloudflare.com

### Configure Cloudflare Zone

1. From Home, click on the domain tile you have just added.
2. You are now in the management portal for your domain. Click on SSL/TLS icon
3. Change the SSL/TLS setting to Off (not secure). We will be doing TLS termination on the ALB as configured by Terraform.
4. Click on Overview. Scroll down until you see Zone ID on the right side. Make note of the Zone ID as you will need this to configure the .tfvars file in the next steps

### Create TLS Certificate in AWS ACM

1. Login to your Amazon AWS account at https://console.aws.amazon.com
2. Go to the Certificate Manager service
3. Click on Request a certificate
4. Ensure you have selected Request a public certificate and click the Request a certificate button
5. Type the wildcard name of the domain you already added to Cloudflare, ex: `*.yourdomain.tld`. If you'd like to secure other sites with the same certificate, such a development zone/environment you can also add this, ex: `*.dev.yourdomain.tld`, `yourdomain.tld`, etc. Click next once you've added sites
6. Select DNS Validation and click Review. With this method, ACM will query your DNS zone to validate you are the legitimate owner
7. Ensure the information in the review screen is correct. Click Confirm and request
8. On the validation screen, you will see CNAME records that will need to exist in your Cloudflare zone you created earlier. Add these records to your Cloudflare zone through https://dash.cloudflare.com. As long as these records exist in DNS, ACM will be able issue new certificates.
9. Once you've added the DNS records to your Cloudflare zone, click Continue.
10. You will be returned to the dashboard to view your TLS certificate. The status will change from Pending Validation to Issued once ACM validates the ownership of the domain. Make note of the ARN in a text file as you will need this to configure the .tfvars file in the next steps

## Deployment Steps

1. In the root of the cloned repo, create a .tfvars file, ex `touch outyet.tfvars`
2. Open the .tfvars file in your favourite text editor, and ensure its populated, substituting:
```hcl
cloudflare_dns_record_name = "<Name of DNS record to alias the load balancer, ex. 'go'"
cloudflare_zone_id         = "<Cloudflare Zone ID recorded earlier from Configure Cloudflare Zone>"
tls_cert_arn               = "<ARN value of TLS cert recorded earlier from Create TLS Certificate in AWS ACM>"
```
3. Ensure you've set your Cloudflare token as an environment variable `export CLOUDFLARE_API_TOKEN=<Cloudflare API token>`
4. Ensure you've set the AWS region to us-east-1 as an environment variable `export AWS_REGION=us-east-1`
5. Initialize Terraform: `terraform init`
6. Run Terraform plan: `terraform plan -var-file=outyet.tfvars`
7. Run Terraform apply: `terraform apply -var-file=outyet.tfvars` and Enter `yes` to proceed with plan
8. Once Terraform has finshed applying, you should be able to curl your DNS record: ex `curl -L go.yourdomain.tld` and receive a response:

```
<!DOCTYPE html><html><body><center>
	<h2>Is Go 1.4 out yet?</h2>
	<h1>
	
		<a href="https://go.googlesource.com/go/&#43;/go1.4">YES!</a>
	
	</h1>
</center></body></html>
```

## Next Steps

- Tagging: None of the resources provisioned are tagged. Will probably need the following tags at the minimum: `Name`, `Environment`(dev/stage/prod/etc), `TerraformManaged` 
- Reusability: More input parameters for Terraform modules, less hardcoding
- Serverless: Refactor the golang app to run in Lambda, this will be a major rearchitecture as an API Gateway may be required amongst other items
- Pipeline: Terraform Cloud currently handles Terraform runs, but may need to move to a different CI service to create a fully integrated pipeline combining the build of the app with deployment via Terraform. GitHub Actions or CircleCI are good candidates

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|:----:|:-----:|:-----:|
| cloudflare\_dns\_record\_name | Name of the CNAME record to alias to the public load balancer record | string | n/a | yes |
| cloudflare\_zone\_id | Zone ID of the Cloudflare zone where record will be created | string | n/a | yes |
| tls\_cert\_arn | The ARN of the TLS certificate to attach to the load balancer listeners | string | n/a | yes |

